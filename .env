# =============================================================================
# Solvathon Layer1 - Voice AI Pipeline Configuration
# Development/Testing Environment for DigitalOcean MI300X GPU
# =============================================================================

# Ollama LLM Configuration (Docker internal DNS)
OLLAMA_BASE_URL=http://ollama:11434

# Speech-to-Text Model
WHISPER_MODEL=openai/whisper-small

# Language Identification Model  
LID_MODEL=facebook/mms-lid-256

# =============================================================================
# TTS Configuration
# =============================================================================
TTS_BACKEND=piper
PIPER_MODELS_DIR=src/tts/piper_models
PIPER_PATH=

# =============================================================================
# Audio Processing
# =============================================================================
SILENCE_THRESHOLD=0.01
SILENCE_DURATION=2.0
MIN_SPEECH_DURATION=1.0

# =============================================================================
# Feature Flags
# =============================================================================
# Enable media-stream WebSocket (used for browser fallback)
ENABLE_TWILIO=true

# Enable automatic language detection
ENABLE_LID_AUTODETECT=true

# Handover mode: 'kiosk' for dev, 'phone' for production
HANDOVER_MODE=kiosk

# Metrics window size
METRICS_WINDOW=200

# =============================================================================
# Redis Configuration (used by redis_context.py)
# =============================================================================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_SESSION_TTL=1800

# =============================================================================
# LLM Model Names (for Ollama)
# =============================================================================
LLM_MODEL=llama3.2:3b
SUMMARIZE_MODEL=llama3.2:1b
EMBED_MODEL=nomic-embed-text

# =============================================================================
# Server Configuration
# =============================================================================
SERVER_HOST=0.0.0.0
SERVER_PORT=8080

# =============================================================================
# Emergency Detection
# =============================================================================
EMERGENCY_CLASSIFIER_PATH=models/emergency_classifier.pt
DISTRESS_WINDOW=5
DISTRESS_MIN_HITS=3
EMERGENCY_THRESHOLD=0.7
